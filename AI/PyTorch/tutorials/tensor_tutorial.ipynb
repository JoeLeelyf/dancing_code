{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Initializing a Tensor\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is automatically inferred.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ],
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "# use torch.tensor() to convert this data to a tensor\n",
        "x_data = torch.tensor(data)\n",
        "print(x_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa - see `bridge-to-np-label`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ],
      "source": [
        "np_array = np.array(data)\n",
        "# use torch.from_numpy() to convert this data to a tensor\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(x_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.1034, 0.1014],\n",
            "        [0.6658, 0.2163]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "# assign a new datatype using dtype parameter\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "``shape`` is a **tuple** of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.6586, 0.3578, 0.8365],\n",
            "        [0.1515, 0.2240, 0.6234]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# (2,3,) , (2,3) and 2,3 are valid\n",
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Attributes of a Tensor\n",
        "\n",
        "Tensor attributes describe their **shape**, **datatype**, and the **device** on which they are stored.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Operations on Tensors\n",
        "\n",
        "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using\n",
        "``.to`` method (after checking for GPU availability). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device tensor is stored on: mps:0\n"
          ]
        }
      ],
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    tensor = tensor.to(\"mps\")\n",
        "\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Standard numpy-like indexing and slicing:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor: \n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(f\"tensor: \\n{tensor}\")\n",
        "# two dimensional matric\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "# : stands for all elements\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "# ... stands for all elements in all dimensions\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Joining tensors** You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n",
        "See also [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)_,\n",
        "another tensor joining operator that is subtly different from ``torch.cat``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Arithmetic operations**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n",
            "2: tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n",
            "3: tensor([[0.7359, 0.6137, 0.2079, 0.6108],\n",
            "        [0.3237, 0.2307, 0.2903, 0.4249],\n",
            "        [0.4836, 0.1105, 0.6870, 0.6097],\n",
            "        [0.6711, 0.8878, 0.6932, 0.3147]])\n",
            "4: tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n",
            "5: tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "6: tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "7: tensor([[0.6374, 0.0277, 0.0167, 0.0278],\n",
            "        [0.4968, 0.8208, 0.3602, 0.4464],\n",
            "        [0.1036, 0.4543, 0.5551, 0.1566],\n",
            "        [0.7755, 0.2551, 0.1972, 0.7824]])\n",
            "8: tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "# dot product\n",
        "y1 = tensor @ tensor.T\n",
        "print(\"1:\",y1)\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "print(\"2:\",y2)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "print(\"3:\",y3)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "print(\"4:\",y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "# element-wise product\n",
        "z1 = tensor * tensor\n",
        "print(\"5:\",z1)\n",
        "z2 = tensor.mul(tensor)\n",
        "print(\"6:\",z2)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "print(\"7:\",z3)\n",
        "torch.mul(tensor, tensor, out=z3)\n",
        "print(\"8:\",z3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Single-element tensors** If you have a one-element tensor, for example by aggregating all\n",
        "values of a tensor into one value, you can convert it to a Python\n",
        "numerical value using ``item()``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(12.)\n",
            "12.0 <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "agg = tensor.sum()\n",
        "print(agg)\n",
        "# use tensor.item() to get the value as a python number from a tensor containing a single value\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "notice that only one element tensors can be converted to Python scalars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_1 = torch.ones(5)\n",
        "# the following line will throw an error\n",
        "# RuntimeError: a Tensor with 5 elements cannot be converted to Scalar\n",
        "# t_1.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**In-place operations**\n",
        "Operations that store the result into the operand are called in-place. They are denoted by a ``_`` suffix.\n",
        "For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ],
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 4. Bridge with NumPy\n",
        "Tensors on the CPU and NumPy arrays can **share their underlying memory\n",
        "locations**, and **changing one will change\tthe other**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensor to NumPy array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A change in the tensor reflects in the NumPy array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NumPy array to Tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Changes in the NumPy array reflects in the tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Other Tensor Operations\n",
        "T stand for specific tensor\n",
        "### `T.view()` or `torch.reshape()` -- Reshaping tensor \n",
        "Use `T.view()` method to change the shape of a tensor without changing its underlying data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# Reshape the tensor\n",
        "y = x.view(3, 2)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the total number of elements in the tensor must remain the same. Use \"-1\" to automatically infer the size of a particular dimension based on the other dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "# The last dimension can be infered through the first dimension,\n",
        "# since it's a two-dimensional tensor\n",
        "y = x.view(2, -1)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also use `torch.reshape()` which has the same functionality, but can be used as a function as well as a method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ],
      "source": [
        "y = torch.reshape(x, (3, 2))\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `torch.argmax()` -- Find the index of the maximum value\n",
        "Use `torch.argmax()` to find the index of the maximum value of a tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters:\n",
        "- input (Tensor) – the input tensor.\n",
        "\n",
        "- dim (int) – the dimension to reduce. If None, the argmax of the flattened input is returned.\n",
        "\n",
        "- keepdim (bool) – whether the output tensor has dim retained or not. Ignored if dim=None."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5827,  0.4513, -0.3963, -1.1931],\n",
            "        [ 1.8570, -0.1275,  0.7349,  0.4797],\n",
            "        [-0.2405, -0.3073, -0.6663, -0.9125],\n",
            "        [ 0.3198, -1.0983,  0.1439,  1.0674]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(4,4)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4)\n",
            "tensor([1, 0, 1, 3])\n",
            "tensor([0, 0, 0, 3])\n"
          ]
        }
      ],
      "source": [
        "print(torch.argmax(a))\n",
        "# dim = 0: find the maximum value in each column\n",
        "print(torch.argmax(a, dim=0))\n",
        "# dim = 1: find the maximum value in each row\n",
        "print(torch.argmax(a, dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `torch.argsort()` -- Returns the indices that sort a tensor along a given dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters:\n",
        "- input (Tensor) – the input tensor.\n",
        "\n",
        "- dim (int, optional) – the dimension to sort along\n",
        "\n",
        "- descending (bool, optional) – controls the sorting order (ascending or descending). Default: False\n",
        "\n",
        "- stable (bool, optional) – controls the relative order of equivalent elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.7889,  0.3980,  0.1023, -0.8025],\n",
            "        [-0.6876, -0.3441,  1.5822,  0.9872],\n",
            "        [ 0.9006, -0.1714,  0.0850,  1.6516],\n",
            "        [ 1.9089,  0.3430, -0.0823,  0.2357]])\n",
            "tensor([[0, 1, 3, 0],\n",
            "        [1, 2, 2, 3],\n",
            "        [2, 3, 0, 1],\n",
            "        [3, 0, 1, 2]])\n",
            "tensor([[3, 0, 2, 1],\n",
            "        [0, 1, 3, 2],\n",
            "        [1, 2, 0, 3],\n",
            "        [2, 3, 1, 0]])\n",
            "tensor([[3, 0, 1, 2],\n",
            "        [2, 3, 0, 1],\n",
            "        [1, 2, 2, 3],\n",
            "        [0, 1, 3, 0]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(4, 4)\n",
        "print(a)\n",
        "# argsort along columns\n",
        "print(torch.argsort(a, dim=0))\n",
        "# argsort along rows\n",
        "print(torch.argsort(a, dim=1))\n",
        "# argsort along columns in descending order\n",
        "print(torch.argsort(a, dim=0, descending=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `T.backword()` -- Compute gradient of current tensor w.r.t. graph leaves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `torch.split()` -- Split tensor into chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters:\n",
        "- tensor (Tensor) – tensor to split.\n",
        "\n",
        "- split_size_or_sections (int) or (list(int)) – size of a single chunk or list of sizes for each chunk. \n",
        "  <br>\n",
        "  If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size. If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks with sizes in dim according to split_size_or_sections.\n",
        "\n",
        "- dim (int) – dimension along which to split the tensor.\n",
        "\n",
        "Return type:\n",
        "- List[Tensor]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7],\n",
            "        [8, 9]])\n",
            "(tensor([[0, 1],\n",
            "        [2, 3]]), tensor([[4, 5],\n",
            "        [6, 7]]), tensor([[8, 9]]))\n",
            "(tensor([[0, 1]]), tensor([[2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7],\n",
            "        [8, 9]]))\n"
          ]
        }
      ],
      "source": [
        "# torch.arange(): return a 1-D tensor of size [end-start] with values from the interval [start, end)\n",
        "a = torch.arange(10).reshape(5, 2)\n",
        "print(a)\n",
        "print(torch.split(a, 2))\n",
        "print(torch.split(a, [1, 4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `torch.squeeze()` -- Returns a tensor with all the dimensions of input of size 1 removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For example, if input is of shape: (A×1×B×C×1×D) then the out tensor will be of shape: (A×B×C×D) .\n",
        "\n",
        "When dim is given, a squeeze operation is done only in the given dimension. If input is of shape: (A×1×B) , squeeze(input, 0) leaves the tensor unchanged, but squeeze(input, 1) will squeeze the tensor to the shape (A×B) ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters:\n",
        "- input (Tensor) – the input tensor.\n",
        "\n",
        "- dim (int or tuple of ints, optional) –\n",
        "\n",
        "    if given, the input will be squeezed\n",
        "only in the specified dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Note*: The returned tensor shares the storage with the input tensor, so changing the contents of one will change the contents of the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 2, 1, 2])\n",
            "torch.Size([2, 2, 2])\n",
            "torch.Size([2, 1, 2, 1, 2])\n",
            "torch.Size([2, 2, 1, 2])\n",
            "torch.Size([2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(2, 1, 2, 1, 2)\n",
        "print(x.size())\n",
        "print(torch.squeeze(x).size())\n",
        "print(torch.squeeze(x, 0).size())\n",
        "print(torch.squeeze(x, 1).size())\n",
        "# dim parameter can also be a tuple\n",
        "print(torch.squeeze(x, (1,2,3)).size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `torch.unsqueeze()` -- Returns a new tensor with a dimension of size one inserted at the specified position."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "torch.unsqueeze(input, dim) → Tensor\n",
        "parameters:\n",
        "- input (Tensor) – the input tensor.\n",
        "- dim(int) – the index at which to insert the singleton dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3, 4]])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1, 2, 3, 4])\n",
        "# equal to torch.unsqueeze(x, 0)\n",
        "print(x.unsqueeze(0))\n",
        "print(x.unsqueeze(1))\n",
        "print(x.unsqueeze(-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `torch.map()` -- Applies a function to each element in the tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we want to apply the same callable to a tensors, we can use `torch.map()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1)\n",
            "tensor(4)\n",
            "tensor(9)\n"
          ]
        }
      ],
      "source": [
        "def f(a):\n",
        "    return a*a\n",
        "t = torch.tensor([1, 2, 3])\n",
        "r = map(f, t)\n",
        "# return a iterator\n",
        "for i in r:\n",
        "    print(i)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
